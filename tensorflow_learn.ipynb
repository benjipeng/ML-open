{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANGE                                 SIZE  STATE REMOVABLE BLOCK\n",
      "0x0000000040000000-0x00000005bfffffff  22G online       yes 8-183\n",
      "\n",
      "Memory block size:       128M\n",
      "Total online memory:      22G\n",
      "Total offline memory:      0B\n"
     ]
    }
   ],
   "source": [
    "!lsmem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "# Build a machine learning model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build A model in Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(T.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = T.nn.Flatten()\n",
    "        self.linear_relu_stack = T.nn.Sequential(\n",
    "            T.nn.Linear(28*28, 512),\n",
    "            T.nn.ReLU(),\n",
    "            T.nn.Linear(512, 512),\n",
    "            T.nn.ReLU(),\n",
    "            T.nn.Linear(512, 10),\n",
    "        )\n",
    "    def forward(self, x): # Operation on input by forward method\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "model = NeuralNetwork().to(\"cpu\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([8])\n"
     ]
    }
   ],
   "source": [
    "X = T.rand(1,28,28,)\n",
    "logits = model(X)\n",
    "pred_probab = T.nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n",
      "torch.Size([3, 784])\n",
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "input_image = T.rand(3,28,28)\n",
    "print(input_image.size())\n",
    "\n",
    "## nn.Flatten\n",
    "flatten = T.nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())\n",
    "\n",
    "## nn.Linear\n",
    "from torch import nn\n",
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nn.Sequential\n",
    "seq_modules = T.nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20,10)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build A model in TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Dense(128, activation='relu')\n",
    "        self.d2 = tf.keras.layers.Dense(10, activation='relu')\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)\n",
    "model = MyModel()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work With Tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A reminder for `PyTorch`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1673,  1.6550,  0.0093,  1.9103, -1.0395]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "torch_randn = t.randn(1,5, dtype=t.double)\n",
    "print(torch_randn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here, with `Tensorflow`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
      "tf.Tensor([3], shape=(1,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[2 4 6]\n",
      " [2 4 6]], shape=(2, 3), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.math.add(1,1))\n",
    "print(tf.math.add([1, 2], [3, 4]))\n",
    "print(tf.math.add( np.array([1]), np.array([2]) ))\n",
    "print(tf.math.add(np.array([[1,2,3],[1,2,3]]),np.array([[1,2,3],[1,2,3]])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work With `DataSets`\n",
    "> `tf.data.Dataset` API for building data pipeline feeding into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1\n",
      "Line 2\n",
      "Line 3\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "ds_tensors = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# Create a CSV file\n",
    "import tempfile\n",
    "_, filename = tempfile.mkstemp() # filename -> str\n",
    "\n",
    "with open(filename, 'w') as f: # \n",
    "    f.write(\"\"\"Line 1\n",
    "Line 2\n",
    "Line 3\n",
    "  \"\"\")\n",
    "\n",
    "with open(filename, 'r') as reader:\n",
    "  print(reader.read())\n",
    "\n",
    "ds_file = tf.data.TextLineDataset(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements of ds_tensors:\n",
      "tf.Tensor([4 9], shape=(2,), dtype=int32)\n",
      "tf.Tensor([16 25], shape=(2,), dtype=int32)\n",
      "tf.Tensor([36  1], shape=(2,), dtype=int32)\n",
      "\n",
      "Elements in ds_file:\n",
      "tf.Tensor([b'Line 1' b'Line 2'], shape=(2,), dtype=string)\n",
      "tf.Tensor([b'Line 3' b'  '], shape=(2,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "ds_tensors = ds_tensors.map(tf.math.square).shuffle(2).batch(2)\n",
    "\n",
    "ds_file = ds_file.batch(2)\n",
    "\n",
    "print('Elements of ds_tensors:')\n",
    "for x in ds_tensors:\n",
    "  print(x)\n",
    "\n",
    "print('\\nElements in ds_file:')\n",
    "for x in ds_file:\n",
    "  print(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work With `Layers`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by wrapping your code in `tf.function`, which replaces Python iteration with the equivalent graph operations using AutoGraph.\n",
    "```python\n",
    "@tf.function\n",
    "def train(model, dataset, optimizer):\n",
    "  for x, y in dataset:\n",
    "    with tf.GradientTape() as tape:\n",
    "      # training=True is only needed if there are layers with different\n",
    "      # behavior during training versus inference (e.g. Dropout).\n",
    "      prediction = model(x, training=True)\n",
    "      loss = loss_fn(prediction, y)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "```\n",
    "***BUT*** If you use the Keras Model.fit API, you `won't` have to worry about dataset iteration.\n",
    "\n",
    "```python\n",
    "model.compile(optimizer=optimizer, loss=loss_fn)\n",
    "model.fit(dataset)\n",
    "```\n",
    "```python\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu',\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(0.02),\n",
    "                           input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Model is the full model w/o custom layers\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, epochs=NUM_EPOCHS)\n",
    "loss, acc = model.evaluate(test_data)\n",
    "\n",
    "print(\"Loss {}, Accuracy {}\".format(loss, acc))\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.function` provides a way to convert **data-dependent** control flow into graph-mode equivalents like `tf.cond` and `tf.while_loop`.\n",
    "```python\n",
    "class DynamicRNN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(DynamicRNN, self).__init__(self)\n",
    "        self.cell = rnn_cell\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec( dtype=tf.float32, shape=[None, None, 3] )])\n",
    "    def call(self,input_data):\n",
    "        # [batch, time, features] -> [time, batch, features]\n",
    "        input_data = tf.transpose(input_data, [1, 0, 2])\n",
    "        timesteps =  tf.shape(input_data)[0]\n",
    "        batch_size = tf.shape(input_data)[1]\n",
    "        outputs = tf.TensorArray(tf.float32, timesteps)\n",
    "        state = self.cell.get_initial_state(batch_size = batch_size, dtype=tf.float32)\n",
    "        for i in tf.range(timesteps):\n",
    "            output, state = self.cell(input_data[i], state)\n",
    "            outputs = outputs.write(i, output)\n",
    "        return tf.transpose(outputs.stack(), [1, 0, 2]), state\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class Net(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = tf.keras.layers.Dense(5)\n",
    "    def call(self, x):\n",
    "        return self.l1(X)\n",
    "net = Net()\n",
    "net.save_weights('ckpts/easy_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tftorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
